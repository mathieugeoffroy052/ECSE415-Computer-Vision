{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from cv2 import VideoCapture\n",
    "import cv2\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir = os.path.curdir\n",
    "# you can find a pretrained model at model/b3.pth\n",
    "MODEL_F = os.path.join(working_dir,'b0.pth')\n",
    "# directory with the numpy optical flow images you want to use for inference\n",
    "OF_NPY_DIR = os.path.join(working_dir, 'test_predictions')\n",
    "#save flows to test_predictions folder as .npy files\n",
    "try:\n",
    "    os.mkdir(OF_NPY_DIR)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run optical flow\n",
    "\n",
    "def calc_flow(img1,img2):\n",
    "    return cv2.calcOpticalFlowFarneback(prev=img1, \n",
    "                                    next=img2, \n",
    "                                    flow=None,\n",
    "                                    pyr_scale=0.5, \n",
    "                                    levels=3, \n",
    "                                    winsize=15,\n",
    "                                    iterations=3, \n",
    "                                    poly_n=5, \n",
    "                                    poly_sigma=1.2, \n",
    "                                    flags=0)\n",
    "def calc_all_flows(video):\n",
    "    ret, prev_frame = video.read()\n",
    "    prev_frame = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "    flows = []\n",
    "    count = 0\n",
    "    while(video.isOpened()):\n",
    "        count += 1\n",
    "        if count % 30 == 0:\n",
    "            print('Processed '+str(count) + ' frames (' +str(count//30) + ' seconds)')\n",
    "        ret, next_frame = video.read()\n",
    "        if ret == True:\n",
    "            next_frame = cv2.cvtColor(next_frame, cv2.COLOR_BGR2GRAY)\n",
    "            flows.append(calc_flow(prev_frame, next_frame))\n",
    "            prev_frame = next_frame\n",
    "        else:\n",
    "            break\n",
    "    return flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flows = calc_all_flows(VideoCapture(os.path.join(working_dir, 'mcgill_drive.mp4')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for i in range(len(flows)):\n",
    "#     np.save(os.path.join(OF_NPY_DIR, 'flow'+str(i)+'.npy'), flows[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if cuda is available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = 0     # what version of efficientnet did you use\n",
    "IN_C = 2  # number of input channels\n",
    "NUM_C = 1 # number of classes to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EfficientNet.from_pretrained(f'efficientnet-b{V}', in_channels=IN_C, num_classes=NUM_C)\n",
    "state = torch.load(MODEL_F, map_location=device)\n",
    "model.load_state_dict(state)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(of_f):\n",
    "    of = np.load(of_f)\n",
    "    print(of.shape)\n",
    "    #change shape from (H,W,2) to (2,H,W)\n",
    "    of = np.transpose(of, (2,0,1))\n",
    "    #add batch dimension\n",
    "    of = np.expand_dims(of, axis=0)\n",
    "    i = torch.from_numpy(of).to(device)\n",
    "    print('running')\n",
    "    pred = model(i)\n",
    "    print(pred)\n",
    "    del i\n",
    "    torch.mps.empty_cache()\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over all files in directory and predict\n",
    "# print(len(Path(OF_NPY_DIR).glob('*.npy')))\n",
    "output = np.zeros(len(os.listdir(OF_NPY_DIR)))\n",
    "for f in sorted(os.listdir(OF_NPY_DIR)):\n",
    "    if f.endswith(\".npy\"):\n",
    "        # print()\n",
    "        y_hat = inference(os.path.join(OF_NPY_DIR,f)).item()\n",
    "        frame_num = int(f.split('.')[0].split('flow')[1])\n",
    "        output[frame_num] = y_hat\n",
    "        print(f'{f}: {round(y_hat, 2)}')\n",
    "        # print(frame_num)\n",
    "\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
